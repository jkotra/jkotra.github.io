<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <base href="/posts/cuda-hello-world/">
    
    

    
    <meta name="description" content="Quick intro to CUDA and a &#39;Hello World&#39; Example" />
    
    
    <meta name="language" content="en">
    <link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml" /> 

    
    
    
    <title>Hello CUDA! :: &lt;stdin&gt;</title>
    

    <link rel="icon" type="image/png" href=/static/chip.png />

    <meta property="og:title" content="Hello CUDA!" />
<meta property="og:description" content="Quick intro to CUDA and a &#39;Hello World&#39; Example" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/cuda-hello-world/" />
<meta property="og:image" content="https://i.imgur.com/9mroRtn.jpg" />
<meta property="article:published_time" content="2020-12-04T18:47:53+05:30" />
<meta property="article:modified_time" content="2020-12-04T18:47:53+05:30" />

    <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://i.imgur.com/9mroRtn.jpg"/>

<meta name="twitter:title" content="Hello CUDA!"/>
<meta name="twitter:description" content="Quick intro to CUDA and a &#39;Hello World&#39; Example"/>


    <meta name="theme-color" content=#2e2847 />

    
    <link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300"
        rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Tangerine&display=swap" rel="stylesheet">    

    
    
    <script src="/js/main.min.ecbcd6a34b475cd2e844a02b80083902ac50d4c1f119178abd429ba42d436bfd4b5529b4a51b9127c9330664e1ad9e846c06f856295b40105bea6d7e2a6c3326.js" integrity="sha512-7LzWo0tHXNLoRKArgAg5AqxQ1MHxGReKvUKbpC1Da/1LVSm0pRuRJ8kzBmThrZ6EbAb4VilbQBBb6m1&#43;KmwzJg=="></script>

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/fontawesome.min.css" integrity="sha512-8jdwayz5n8F2cnW26l9vpV6+yGOcRAqz6HTu+DQ3FtVIAts2gTdlFZOGpYhvBMXkWEgxPN3Y22UWyZXuDowNLA==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/regular.min.css" integrity="sha512-qgtcTTDJDk6Fs9eNeN1tnuQwYjhnrJ8wdTVxJpUTkeafKKP6vprqRx5Sj/rB7Q57hoYDbZdtHR4krNZ/11zONg==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/brands.min.css" integrity="sha512-AMDXrE+qaoUHsd0DXQJr5dL4m5xmpkGLxXZQik2TvR2VCVKT/XRPQ4e/LTnwl84mCv+eFm92UG6ErWDtGM/Q5Q==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/solid.min.css" integrity="sha512-QN7X/bUbbeel9bbq6JVNJXk1Zowt+n+QPN+DjhEmTa4TdL1YPCsCey5JrvfRW8xp28LDYgGG/waNVdrhwMQmVQ==" crossorigin="anonymous" />
    
    
    
    <link rel="stylesheet" type="text/css" media="screen" href="/css/main.min.11e4fae581d29b4f1d9ee81e1c11e70ef64db60ae869076aa75b9212ffe3098417b4019c294384255339a37a864d37e4dd7a55ee05fd953536c1ddc11bf952a2.css" integrity="sha512-EeT65YHSm08dnugeHBHnDvZNtgroaQdqp1uSEv/jCYQXtAGcKUOEJVM5o3qGTTfk3XpV7gX9lTU2wd3BG/lSog==" />
    
    <link rel="stylesheet" type="text/css" media="screen" href="/css/custom.min.3e90b71df5994759c01a2c012d044795212a2436d2b36597893f83e31af62525d4571cc4135b3c4c2c634e0101d0c8e04be3d971ac8378e1ca15bf7d67d64eea.css" integrity="sha512-PpC3HfWZR1nAGiwBLQRHlSEqJDbSs2WXiT&#43;D4xr2JSXUVxzEE1s8TCxjTgEB0MjgS&#43;PZcayDeOHKFb99Z9ZO6g==" />
    
    
    <link rel="stylesheet" type="text/css" href="/css/dark.min.a6e1132ca354fccc5b438d5409cb8472d273c4d4df9bfc966733b6834ac01013a955ce583e386b9ed5bc2a5217255129b6389867b03bfa3b19ed78677816669a.css" media="(prefers-color-scheme: dark)">


    
    <link rel="stylesheet" type="text/css" media="screen" href="/css/normalize.min.112c04d26fa13a6d29cec753a0959b82339c03760baa50dc705accbb85d7b83e02b7a3691b24d116b6e619c311eacb3f2f96529bcf0b45d8ae35759f9f35d52e.css" integrity="sha512-ESwE0m&#43;hOm0pzsdToJWbgjOcA3YLqlDccFrMu4XXuD4Ct6NpGyTRFrbmGcMR6ss/L5ZSm88LRdiuNXWfnzXVLg==" />


    
    

    

    

    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YW8V9DTR0N"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', "G-YW8V9DTR0N" );
</script>



    
    <script data-ad-client=ca-pub-8658473214995139 async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    

</head>

<body>
    <div class="container wrapper">
    <div class="header">
	<base href="/">
	<h1 class="site-title">
		
		<a href="/">&lt;stdin&gt;</a>
		
		<span class="blinking-cursor">|</span>
		
	</h1>

	<div class="site-description">
		
		<h2 class="cursive">My Thoughts, Trials and Adventures</h2>
		

		<nav class="nav social">
			<ul class="flat">
				
				<a href="mailto:jagadeesh@stdin.top" title="Mail"><i class="far fa-envelope"></i></a>
				
				<a href="https://github.com/jkotra/" title="Github"><i class="fab fa-github"></i></a>
				
				<a href="https://twitter.com/jagadeesh_kotra" title="Twitter"><i class="fab fa-twitter"></i></a>
				
				<a href="index.xml" title="RSS"><i class="fas fa-rss"></i></a>
				
			</ul>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/about/">About</a>
			</li>
			
			<li>
				<a href="/tags/">Tags</a>
			</li>
			
			<li>
				<a href="/portfolio/">Portfolio</a>
			</li>
			
			<li>
				<a href="/pgp/">PGP</a>
			</li>
			
		</ul>
	</nav>
</div>

    
<div class= "post">
<div class="post-header">
	<h1 class="title">Hello CUDA!</h1>
	
	<div class="meta">Posted at &mdash; Dec 4, 2020</div>
	
</div>

<div class="markdown">
	<h1 id="introduction">Introduction</h1>
<p>CUDA is a parallel computing platform and application programming interface model created by Nvidia. It allows software developers and software engineers to use a CUDA-enabled graphics processing unit for general-purpose processing â€“ an approach termed GPGPU.</p>
<p><strong>CUDA</strong> programs are compiled using <a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">NVCC</a>. NVCC is included with <a href="https://developer.nvidia.com/cuda-toolkit">CUDA toolkit</a>.</p>
<h2 id="building-blocks">Building Blocks</h2>
<h3 id="block">Block</h3>
<p>A group of threads is called a <strong>CUDA block</strong>. <strong>CUDA blocks</strong> are grouped into a grid. A kernel is executed as a grid of <strong>blocks</strong> of threads</p>
<h3 id="thread">Thread</h3>
<p><code>Total no of Threads = No Blocks x Threads Per Block</code></p>
<hr>
<h2 id="hello-world">Hello World</h2>
<div class="notices note" ><p><a href="https://github.com/jkotra/cuda_samples/tree/main/hello_world">Code on Github</a></p></div>
<p>Demonstration and code walkthrough of a simple <code>Hello World</code> program.</p>
<p>To run this, clone the repository and run <code>make</code> command.</p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#099">#include</span><span style="color:#099">&lt;stdio.h&gt;</span><span style="color:#099">
</span><span style="color:#099">#include</span><span style="color:#099">&lt;stdlib.h&gt;</span><span style="color:#099">
</span><span style="color:#099"></span>
__global__ <span style="color:#078;font-weight:bold">void</span> <span style="color:#c0f">from_gpu</span>(<span style="color:#078;font-weight:bold">void</span>){

    printf(<span style="color:#c30">&#34;%d, %d</span><span style="color:#c30;font-weight:bold">\n</span><span style="color:#c30">&#34;</span>, blockIdx.x, threadIdx.x);

}

<span style="color:#078;font-weight:bold">int</span> <span style="color:#c0f">main</span>(){

    from_gpu<span style="color:#555">&lt;&lt;&lt;</span><span style="color:#f60">10</span>, <span style="color:#f60">10</span><span style="color:#555">&gt;&gt;&gt;</span>();
    cudaDeviceSynchronize();

    <span style="color:#069;font-weight:bold">return</span> <span style="color:#f60">0</span>;
}
</code></pre></div><p>Output:</p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">0, 0
0, 1
0, 2
0, 3
0, 4
0, 5
0, 6
....
....
....
7, 5
7, 6
7, 7
7, 8
7, 9
</code></pre></div><hr>
<h2 id="vector-addition">Vector Addition</h2>
<div class="notices note" ><p><a href="https://github.com/jkotra/cuda_samples/tree/main/vec_add">Code on Github</a></p></div>
<p>To demonstrate the power of CUDA, let&rsquo;s take <strong>vector multiplication</strong> as an example.</p>
<p>This example has 2 files:</p>
<ul>
<li><a href="https://github.com/jkotra/cuda_samples/blob/main/vec_add/vec_add.cpp">vec_add.cpp</a></li>
<li><a href="https://github.com/jkotra/cuda_samples/blob/main/vec_add/vec_add_k.cu">vec_add_k.cu</a></li>
</ul>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#099">#include</span> <span style="color:#099">&lt;iostream&gt;</span><span style="color:#099">
</span><span style="color:#099">#include</span> <span style="color:#099">&lt;random&gt;</span><span style="color:#099">
</span><span style="color:#099">#include</span> <span style="color:#099">&lt;vector&gt;</span><span style="color:#099">
</span><span style="color:#099">#include</span> <span style="color:#099">&lt;algorithm&gt;</span><span style="color:#099">
</span><span style="color:#099"></span>
<span style="color:#099">#include</span> <span style="color:#099">&#34;vec_add_k.cuh&#34;</span><span style="color:#099">
</span><span style="color:#099"></span>
<span style="color:#078;font-weight:bold">int</span> <span style="color:#c0f">main</span>(){

    std<span style="color:#555">::</span>vector<span style="color:#555">&lt;</span><span style="color:#078;font-weight:bold">int</span><span style="color:#555">&gt;</span> a(<span style="color:#f60">100</span>), b(<span style="color:#f60">100</span>);

    std<span style="color:#555">::</span>generate(a.begin(), a.end(), [<span style="color:#555">&amp;</span>](){ <span style="color:#069;font-weight:bold">return</span> std<span style="color:#555">::</span>rand() <span style="color:#555">%</span> <span style="color:#f60">10</span>; });
    std<span style="color:#555">::</span>generate(b.begin(), b.end(), [<span style="color:#555">&amp;</span>](){ <span style="color:#069;font-weight:bold">return</span> std<span style="color:#555">::</span>rand() <span style="color:#555">%</span> <span style="color:#f60">10</span>; });

    <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>result <span style="color:#555">=</span> add_vec(a.data(), b.data());

    <span style="color:#069;font-weight:bold">for</span> (<span style="color:#078;font-weight:bold">int</span> i <span style="color:#555">=</span> <span style="color:#f60">0</span>; i <span style="color:#555">&lt;</span> <span style="color:#f60">100</span>; i<span style="color:#555">++</span>)
    {
        std<span style="color:#555">::</span>cout <span style="color:#555">&lt;&lt;</span> a.at(i) <span style="color:#555">&lt;&lt;</span> <span style="color:#c30">&#34;+&#34;</span> <span style="color:#555">&lt;&lt;</span> b.at(i) <span style="color:#555">&lt;&lt;</span> <span style="color:#c30">&#34;=&#34;</span> <span style="color:#555">&lt;&lt;</span> result[i] <span style="color:#555">&lt;&lt;</span> std<span style="color:#555">::</span>endl;
    }

    <span style="color:#069;font-weight:bold">return</span> <span style="color:#f60">0</span>;
}
</code></pre></div><p>In <code>vec_add.cpp</code>, 2 vectors are defined and are filled with random numbers. These two vectors are then passed to CUDA kernel for computation.</p>
<h3 id="cuda-kernel">CUDA Kernel</h3>
<p>we start by importing standard library</p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#099">#include</span> <span style="color:#099">&lt;iostream&gt;</span><span style="color:#099">
</span></code></pre></div><p>create a function called <code>add_vec</code> this takes in the vector from our program <code>vec_add.cpp</code></p>
<p>declare variables for device storage. (<code>d_a</code>, <code>d_b</code>, <code>d_c</code>)
to store the result, declare a variable <code>c</code> and allocate memory.</p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#078;font-weight:bold">int</span><span style="color:#555">*</span> <span style="color:#c0f">add_vec</span>(<span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>a, <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>b){

    <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>d_a, <span style="color:#555">*</span>d_b, <span style="color:#555">*</span>d_c;
    <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>c;
    c <span style="color:#555">=</span> (<span style="color:#078;font-weight:bold">int</span><span style="color:#555">*</span>) malloc(<span style="color:#069;font-weight:bold">sizeof</span>(<span style="color:#078;font-weight:bold">int</span>) <span style="color:#555">*</span> <span style="color:#f60">100</span>);
</code></pre></div><p>compute the size of storage required, Note that we generated 100 randoms numbers each in both vectors.</p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#078;font-weight:bold">int</span> size <span style="color:#555">=</span> <span style="color:#f60">100</span> <span style="color:#555">*</span> <span style="color:#069;font-weight:bold">sizeof</span>(<span style="color:#078;font-weight:bold">int</span>);
</code></pre></div><p>allocate memory to device variable&rsquo;s using <code>cudaMalloc()</code></p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp">    cudaMalloc(<span style="color:#555">&amp;</span>d_a, size);
    cudaMalloc(<span style="color:#555">&amp;</span>d_b, size);
    cudaMalloc(<span style="color:#555">&amp;</span>d_c, size);
</code></pre></div><p>Copy host variables into device variables:</p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp">    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_c, c, size, cudaMemcpyHostToDevice);
</code></pre></div><p>Finally Launch the kernel:</p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp">add_vec_cuda<span style="color:#555">&lt;&lt;&lt;</span><span style="color:#f60">1</span>, <span style="color:#f60">100</span><span style="color:#555">&gt;&gt;&gt;</span>(d_a, d_b, d_c);
</code></pre></div><p>the numbers inside the triple arrow i.e <code>&lt;&lt;&lt;</code> and <code>&gt;&gt;&gt;</code> define the size of the kernel, the above line will launch 1 block with 100 threads.</p>
<p><a href="https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/">More on it</a></p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp">__global__ <span style="color:#078;font-weight:bold">void</span> <span style="color:#c0f">add_vec_cuda</span>(<span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>a, <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>b, <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>c){

    <span style="color:#078;font-weight:bold">int</span> index <span style="color:#555">=</span> blockDim.x <span style="color:#555">*</span> blockIdx.x <span style="color:#555">+</span> threadIdx.x;
    
    <span style="color:#069;font-weight:bold">if</span> (index <span style="color:#555">&lt;</span> <span style="color:#f60">100</span>){
        c[index] <span style="color:#555">=</span> a[index] <span style="color:#555">+</span> b[index]; 
    }

}
</code></pre></div><p>This is where the magic happens, the result of the addition of vector(s) can be calculated independent of other elements in the array. Taking advantage of massive no of Cuda cores and threads, operations like these can be accelerated many times compared to a typical CPU.</p>
<p>index can be calculated like below:</p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#078;font-weight:bold">int</span> index <span style="color:#555">=</span> blockDim.x <span style="color:#555">*</span> blockIdx.x <span style="color:#555">+</span> threadIdx.x;
</code></pre></div><p>This is one of the main limitations of CUDA, things work a lit bit differently inside CUDA kernel.</p>
<p>
  <img src="https://i.imgur.com/zVDXn7E.png" alt="">
(Credits: <a href="http://study.marearts.com/2015/03/meaning-of-threadidx-blockidx-blockdim.html">http://study.marearts.com/2015/03/meaning-of-threadidx-blockidx-blockdim.html</a>)</p>
<p><code>if</code> condition is used to prevent memory overflow, this can be useful in the case of variable input size.</p>
<p>Complete code:</p>
<div class="highlight"><pre style="background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#09f;font-style:italic">// vec_add_k.cu
</span><span style="color:#09f;font-style:italic"></span>
<span style="color:#099">#include</span> <span style="color:#099">&lt;iostream&gt;</span><span style="color:#099">
</span><span style="color:#099"></span>
__global__ <span style="color:#078;font-weight:bold">void</span> <span style="color:#c0f">add_vec_cuda</span>(<span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>a, <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>b, <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>c){

    <span style="color:#078;font-weight:bold">int</span> index <span style="color:#555">=</span> blockDim.x <span style="color:#555">*</span> blockIdx.x <span style="color:#555">+</span> threadIdx.x;
    
    <span style="color:#069;font-weight:bold">if</span> (index <span style="color:#555">&lt;</span> <span style="color:#f60">100</span>){
        c[index] <span style="color:#555">=</span> a[index] <span style="color:#555">+</span> b[index]; 
    }

}

<span style="color:#078;font-weight:bold">int</span><span style="color:#555">*</span> <span style="color:#c0f">add_vec</span>(<span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>a, <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>b){

    <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>d_a, <span style="color:#555">*</span>d_b, <span style="color:#555">*</span>d_c;
    <span style="color:#078;font-weight:bold">int</span> <span style="color:#555">*</span>c;

    c <span style="color:#555">=</span> (<span style="color:#078;font-weight:bold">int</span><span style="color:#555">*</span>) malloc(<span style="color:#069;font-weight:bold">sizeof</span>(<span style="color:#078;font-weight:bold">int</span>) <span style="color:#555">*</span> <span style="color:#f60">100</span>);

    <span style="color:#078;font-weight:bold">int</span> size <span style="color:#555">=</span> <span style="color:#f60">100</span> <span style="color:#555">*</span> <span style="color:#069;font-weight:bold">sizeof</span>(<span style="color:#078;font-weight:bold">int</span>);

    cudaMalloc(<span style="color:#555">&amp;</span>d_a, size);
    cudaMalloc(<span style="color:#555">&amp;</span>d_b, size);
    cudaMalloc(<span style="color:#555">&amp;</span>d_c, size);

    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_c, c, size, cudaMemcpyHostToDevice);

    add_vec_cuda<span style="color:#555">&lt;&lt;&lt;</span><span style="color:#f60">1</span>, <span style="color:#f60">100</span><span style="color:#555">&gt;&gt;&gt;</span>(d_a, d_b, d_c);

    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);

    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    <span style="color:#069;font-weight:bold">return</span> c;
}
</code></pre></div><h2 id="whats-next">What&rsquo;s Next?</h2>
<p>This post serves as an example-first intro to CUDA, I skipped a lot of jargon about CUDA and NVIDIA architecture. I intend to cover some important topics like Matrix Multiplication and Image processing in future articles :bowtie:</p>

</div>

<div class="post-tags">
	
	
	
</div>

<div id="commento"></div>

<script id="comments" src="https://utteranc.es/client.js" repo="jkotra/stdin.top-comments" issue-term="pathname"
	label="ðŸ’¬" theme="github-light" crossorigin="anonymous" async>
	</script>

<noscript>Please enable JavaScript to view the
	<a href="https://commento.io/">comments powered by Commento.</a>
</noscript>

</div>





<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>



</div>


    </div>

    <div class="footer wrapper">

			
			
			<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-8658473214995139"
     data-ad-slot="2398602558"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<br>
			

	<nav class="nav">
		<div class="badge"><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="/cc/by-sa.png"></a></div>
		<div> <a href="https://github.com/jkotra/kavi-hugo-theme">Kavi</a> (based on <a href="https://github.com/vividvilla/ezhil">ezhil</a>)</a> | Built with <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>

</body>

</html>